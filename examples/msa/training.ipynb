{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVs1eelGRwcp",
        "user_expressions": []
      },
      "source": [
        "# GPN-MSA: training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff_VhW6GciQ-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#!pip install --quiet git+https://github.com/songlab-cal/gpn.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "d40QVpqUoD4J"
      },
      "outputs": [],
      "source": [
        "# Data sources and output\n",
        "# see README for how to download and unzip MSA:\n",
        "# https://huggingface.co/datasets/songlab/multiz100way\n",
        "msa_path = \"/local/scratch/gpn/89.zarr\"\n",
        "training_windows_path = \"songlab/gpn-msa-sapiens-dataset\"\n",
        "output_path = \"checkpoints\"  # TODO: might need to do mkdir\n",
        "\n",
        "# Hyperparameters\n",
        "max_steps = 10 # just for demonstration, should be 30_000 in a real run\n",
        "loss_weight = 0.1\n",
        "seed = 42\n",
        "use_aux_features = True\n",
        "weight_conserved = True\n",
        "flip_nonconserved = True\n",
        "n_aux_features = 89 * 5 # (n_species * #{A,C,G,T,-})\n",
        "config_overrides = f\"n_aux_features={n_aux_features}\"  # here you can add e.g. ,hum_hidden_layers=8\n",
        "\n",
        "# System-specific config\n",
        "# The recommended total batch size is 2048\n",
        "# Since I'm running this notebook with 1 GPU, I'll put per_device_batch_size=512\n",
        "# and gradient_accumulation_steps=4\n",
        "n_gpu = 1\n",
        "per_device_batch_size = 512 # whatever fits in your GPU\n",
        "gradient_accumulation_steps = 4\n",
        "dataloader_num_workers = 8  # number of CPUs\n",
        "torchrun_path = \"~/.conda/envs/hugging_face_env/bin/torchrun\"  # might just be \"torchrun\" in your system\n",
        "report_to = \"none\"  # we usually use wandb (might need to create an account)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IxOIcRenoD4K"
      },
      "outputs": [],
      "source": [
        "!WANDB_PROJECT=GPN_MSA_SAPIENS_EXAMPLE {torchrun_path} --nproc_per_node={n_gpu} -m gpn.msa.train --do_train \\\n",
        "    --do_eval --fp16 --report_to {report_to} --prediction_loss_only True \\\n",
        "    --dataset_name {training_windows_path} \\\n",
        "    --msa_path {msa_path} \\\n",
        "    --run_name example1 --output_dir {output_path} \\\n",
        "    --soft_masked_loss_weight_train {loss_weight} \\\n",
        "    --soft_masked_loss_weight_evaluation {loss_weight} \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --optim adamw_torch --learning_rate 1e-4 --lr_scheduler_type cosine \\\n",
        "    --seed {seed} \\\n",
        "    --dataloader_num_workers {dataloader_num_workers} \\\n",
        "    --save_strategy steps --save_steps 5000 --evaluation_strategy steps \\\n",
        "    --eval_steps 5000 --logging_steps 5000 --max_steps {max_steps} \\\n",
        "    --warmup_steps 1000 --save_total_limit 1 --load_best_model_at_end \\\n",
        "    --model_type GPNRoFormer --config_overrides {config_overrides} \\\n",
        "    --use_aux_features {use_aux_features} \\\n",
        "    --weight_conserved {weight_conserved} \\\n",
        "    --flip_nonconserved {flip_nonconserved} \\\n",
        "    --remove_unused_columns False \\\n",
        "    --per_device_train_batch_size {per_device_batch_size} \\\n",
        "    --per_device_eval_batch_size {per_device_batch_size} \\\n",
        "    --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
        "    --torch_compile"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gpn",
      "language": "python",
      "name": "gpn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}